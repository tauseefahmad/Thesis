{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20cccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Intersection values computation for the case when datasets are taken at their full size\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from itertools import combinations, repeat\n",
    "from pathos.multiprocessing import ProcessingPool as Pool, cpu_count\n",
    "import seaborn as sns\n",
    "import multiprocessing\n",
    "import logging\n",
    "logging.basicConfig(filename='log_ch.txt',level=logging.INFO)\n",
    "\n",
    "from chgen.wrapper import find_loss, compute_intersections\n",
    "\n",
    "# define a dimension (number of features in a combination) and names to the dataframes\n",
    "# that are used for calculations. The same names must be used for intersection value\n",
    "\n",
    "dim = 2\n",
    "df_names = ['eICU', 'uka']\n",
    "logging.info(f'CURRENT PAIR: {df_names[0]} and {df_names[1]}')\n",
    "logging.info(f'CURRENT DIMENSION: {dim}')\n",
    "\n",
    "# prepare dataframes and their features\n",
    "\n",
    "\n",
    "df = pd.read_csv('') # eICU dataset\n",
    "df2 = pd.read_csv('') # uka dataset\n",
    "\n",
    "\n",
    "\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a6cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.drop(columns = ['Albumin','Troponin','P_EI (peak endinsp.)','CRP','Amylase','BNP'], inplace = True)\n",
    "df_2.drop(columns = ['Albumin','Troponin','P_EI (peak endinsp.)','CRP','Amylase','BNP'], inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ab9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# find common parameters for both dataframes\n",
    "common_params = sorted(list(set(df_1.columns).intersection(df_2.columns)))\n",
    "logging.info(f'Number of common parameters: {len(common_params)} for {df_names[0]} and {df_names[1]}')\n",
    "logging.info(f'Common parameters for {df_names[0]} and {df_names[1]}: {common_params}')\n",
    "\n",
    "df_1 = df_1[common_params]\n",
    "df_2 = df_2[common_params]\n",
    "\n",
    "# create a list with all combinations of parameters for a defined dimension\n",
    "combos = list(combinations(common_params, dim))\n",
    "logging.info(f'Number of combos: {len(combos)} for {df_names[0]} and {df_names[1]}')\n",
    "\n",
    "# store the results\n",
    "os.makedirs('./eICU_uka_results', exist_ok = True)\n",
    "\n",
    "common_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6385dc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# find outliers\n",
    "eps = 0.5 #neighborhood distance of a point\n",
    "min_samples = 4 #minimal number of neighbors of a point\n",
    "not_noise = 0.9 #amount of points that form a cluster, i.e. it is allowed to have 10% of ouliers at most\n",
    "\n",
    "# first dataset\n",
    "result_bools_1 = [] # container for a point identification, True - part of a cluster, False - an outlier\n",
    "df_loss = pd.DataFrame(columns = ['Combination','Loss','end_eps','end_sample'])\n",
    "idx = 0\n",
    "for combo in combos:\n",
    "    bools, curr_combo, loss, end_eps, end_sample = find_loss(combo, df_1, df_names[0], eps, min_samples, not_noise)\n",
    "    result_bools_1.append(bools)\n",
    "    df_loss.loc[idx, 'Combination'] = curr_combo\n",
    "    df_loss.loc[idx, 'Loss'] = loss\n",
    "    df_loss.loc[idx, 'end_eps'] = end_eps\n",
    "    df_loss.loc[idx, 'end_sample'] = end_sample\n",
    "    idx += 1\n",
    "df_loss.to_csv(f'./eICU_uka_results/end_eps_for_{df_names[0]}_in_pair_w_{df_names[1]}_full.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3847e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# second dataset\n",
    "result_bools_2 = []\n",
    "df_loss = pd.DataFrame(columns = ['Combination','Loss','end_eps','end_sample'])\n",
    "idx = 0\n",
    "for combo in combos:\n",
    "    bools, curr_combo, loss, end_eps, end_sample = find_loss(combo, df_2, df_names[1], eps, min_samples, not_noise)\n",
    "    result_bools_2.append(bools)\n",
    "    df_loss.loc[idx, 'Combination'] = curr_combo\n",
    "    df_loss.loc[idx, 'Loss'] = loss\n",
    "    df_loss.loc[idx, 'end_eps'] = end_eps\n",
    "    df_loss.loc[idx, 'end_sample'] = end_sample\n",
    "    idx += 1\n",
    "df_loss.to_csv(f'./eICU_uka_results/end_eps_for_{df_names[1]}_in_pair_w_{df_names[0]}_full.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15c9c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# computation of intersection values with all points (outliers included) without sampling of instances\n",
    "logging.info(f'BEFORE DBSCAN, {df_names[1]} is fixed')\n",
    "df_1_in_2 = pd.DataFrame()\n",
    "for combo in combos:\n",
    "    df_curr = compute_intersections(combo = combo, df_1 = df_1, df_2 = df_2, df_names = df_names,\n",
    "                                    bools_1 = [], bools_2 = [], first_fixed = None)\n",
    "    df_1_in_2 = pd.concat([df_1_in_2, df_curr])\n",
    "df_1_in_2.to_csv(f\"./eICU_uka_results/full_{df_names[0]}_and_full_{df_names[1]}_all_points.csv\", index=False)\n",
    "\n",
    "# computation of intersection values after outlier removal without sampling of instances\n",
    "logging.info(f'AFTER DBSCAN, {df_names[1]} is fixed')\n",
    "df_1_in_2 = pd.DataFrame()\n",
    "for combo, bool_1, bool_2 in zip(combos, result_bools_1, result_bools_2):\n",
    "    df_curr = compute_intersections(combo = combo, df_1 = df_1, df_2 = df_2, df_names = df_names,\n",
    "                                    bools_1 = bool_1, bools_2 = bool_2, first_fixed = None)\n",
    "    df_curr.to_csv(f\"./eICU_uka_results/{combo}_wo_outliers.csv\", index=False)\n",
    "    df_1_in_2 = pd.concat([df_1_in_2, df_curr])\n",
    "#df_1_in_2.to_csv(f\"./eICU_uka_results/full_{df_names[0]}_and_full_{df_names[1]}_wo_outliers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc7c63e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
